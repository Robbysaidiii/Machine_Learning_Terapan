# -*- coding: utf-8 -*-
"""Robbysaidi_Machine Learning Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tJ4StAxSveK83h4Y-m2YUdDuRVjgpanS

#Import library
"""

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import joblib
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""1.   import dataset yang dibutuhkan untuk klasifikasi

#Load dataset
"""

drive.mount('/content/drive')

"""2. menghubungkan ke google drive"""

data = pd.read_csv('/content/drive/MyDrive/data_cuaca.csv', delimiter=';')

"""3. mengambil data_cuaca.csv yang ada didalam google drive lalu menyimpan nya didalam varibel data"""

data

"""1. Dataset ini berisi data cuaca harian yang terdiri dari 9 kolom dan 719 baris.
2. Kolom `Thn`, `bln`, dan `tgl` menunjukkan informasi waktu: tahun, bulan, dan tanggal pencatatan.
3. `temp_min`, `temp_max`, dan `temp_rata-rata` mencerminkan suhu minimum, maksimum, dan rata-rata harian dalam derajat Celcius.
4. `lembab_rata-rata` menunjukkan kelembaban udara rata-rata harian dalam persen.
5. `ch` merupakan curah hujan harian dalam milimeter, yang menjadi target utama untuk klasifikasi cuaca.
6. `cahaya_jam` mencatat lama penyinaran matahari dalam jam per hari.
7. Data ini digunakan untuk mengklasifikasikan intensitas hujan: tidak hujan, hujan ringan, hujan sedang, atau hujan deras.
8. Fitur-fitur seperti suhu, kelembaban, dan cahaya matahari sangat berpengaruh dalam menentukan curah hujan.
9. Dataset ini cocok digunakan dalam model klasifikasi seperti Random Forest untuk prediksi cuaca.
10. Dengan preprocessing dan pelabelan yang tepat, data ini dapat membantu membangun sistem prediksi cuaca otomatis.

#**Exploratory Data Analysis**
"""

data.describe()

"""- count: 718 â€” Terdapat 718 entri valid dari total 719, artinya ada 1 data hilang.

- mean: 37,40Â°C â€” Terlalu tinggi untuk suhu minimum, mengindikasikan adanya outlier.

- std: 372,28Â°C â€” Variasi sangat tinggi dan tidak wajar, memperkuat dugaan adanya nilai ekstrem.

- min: 18,2Â°C â€” Nilai terendah yang masuk akal untuk suhu minimum.

- 25%: 23,2Â°C â€” Seperempat data memiliki suhu minimum di bawah nilai ini.

- median (50%): 23,8Â°C â€” Setengah data memiliki suhu minimum di bawah 23,8Â°C.

- 75%: 24,4Â°C â€” Seperempat data memiliki suhu minimum di atas nilai ini.

- max: 9999,0Â°C â€” Jelas merupakan error input dan harus dibersihkan.



1. Beberapa kolom seperti temp_min, temp_max, ch, dan cahaya_jam mengandung outlier ekstrem (9999, 8888) yang tidak valid dan harus dibersihkan atau diimputasi.


"""

data.info()

"""-Terdapat 719 baris data, artinya data terdiri dari 719 hari pengamatan (mungkin harian dari 2022 hingga 2023).

- type data nya hanya 2 float sebanyak 6 colom dan int sebanyak 3 colom

## duplikat
"""

data.duplicated().sum()

"""tidak ada nilai terduplikat

##Missing value
"""

data_clean=data.replace([9999, 8888], pd.NA, inplace=True)

""" menangani data yang tidak valid atau error."""

# Menampilkan jumlah nilai yang hilang (missing/NaN) per kolom
missing_per_column = data.isnull().sum()
print(missing_per_column[missing_per_column > 0])

"""terdapat nilai missing value. nilai ini janga di hapus tapi kita isi dengan nilai rata-rata, median,"""

Thn = data['Thn']
bln = data['bln']
tgl = data['tgl']
temp_min = data['temp_min']
temp_max = data['temp_max']
temp_rata_rata = data['temp_rata-rata']
lembab_rata_rata = data['lembab_rata-rata']
ch = data['ch']
cahaya_jam = data['cahaya_jam']

"""untuk memudahkan saya membuat variabel baru dari colom"""

temp_min.fillna(temp_min.median(), inplace=True)
temp_max.fillna(temp_max.median(), inplace=True)
temp_rata_rata.fillna(temp_rata_rata.median(), inplace=True)
ch.fillna(ch.median(), inplace=True)
cahaya_jam.fillna(cahaya_jam.median(), inplace=True)

print(temp_min.isnull().sum())
print(temp_max.isnull().sum())
print(temp_rata_rata.isnull().sum())
print(ch.isnull().sum())
print(cahaya_jam.isnull().sum())

"""0 ini berarti nilai nya tidak ada nilai yang NaN (Data bersih)

##Outliers
"""

import pandas as pd

# Misalnya ini daftar kolom yang ingin dicek
numerik_cols = ['temp_min', 'temp_max', 'temp_rata-rata', 'lembab_rata-rata', 'ch', 'cahaya_jam']
Outlier = (Thn, bln, tgl, temp_min, temp_max, temp_rata_rata, lembab_rata_rata, ch, cahaya_jam)

# Mengecek outlier untuk tiap kolom
for i, col in enumerate(numerik_cols):
    current_series = Outlier[i]
    Q1 = current_series.quantile(0.25)
    Q3 = current_series.quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = current_series[(current_series < lower_bound) | (current_series > upper_bound)]

    print(f"Kolom: {col}")
    print(f"Jumlah outlier: {outliers.shape[0]}")
    print("-" * 40)

"""outlier disini tidak boleh dihilangkan karena saya akan melakukan prediksi dimasa depan 2024"""

plt.figure(figsize=(15, 8))

for i, col in enumerate(numerik_cols):
    plt.subplot(3, 3, i+1)
    sns.boxplot(y=Outlier[i])
    plt.title(f'{col}')
    plt.tight_layout()

plt.show()

"""visual dari outlier di lembab, ch, cahaya_jam"""

import matplotlib.pyplot as plt

fitur = (temp_min, temp_max, temp_rata_rata, lembab_rata_rata, ch, cahaya_jam)
labels = ['temp_min', 'temp_max', 'temp_rata-rata', 'lembab_rata-rata', 'ch', 'cahaya_jam']

n = len(fitur)

fig, axes = plt.subplots(2, 3, figsize=(20, 15))  # Ukuran besar
axes = axes.flatten()

for i, feature in enumerate(fitur):
    axes[i].hist(feature, bins=50, color='skyblue', edgecolor='black')
    axes[i].set_title(f'Distribusi {labels[i]}')
    axes[i].set_xlabel(labels[i])
    axes[i].set_ylabel('Frekuensi')

plt.tight_layout()
plt.show()

""" 1. Suhu Minimum (temp_min)
Rentang antara 18Â°C hingga 26Â°C.

Distribusi miring ke kanan (positif skew).

Puncak di sekitar 24Â°C.

Kesimpulan: Suhu minimum harian cenderung stabil dan cukup hangat, dengan sebagian besar hari berada pada kisaran nyaman sekitar 24Â°C.

ğŸ”¹ 2. Suhu Maksimum (temp_max)
Rentang antara 20Â°C hingga 37Â°C.

Distribusi juga miring ke kanan.

Puncak di sekitar 32.5Â°C.

Kesimpulan: Suhu maksimum bervariasi lebih luas, dengan banyak hari panas (30â€“35Â°C), mengindikasikan iklim tropis atau subtropis yang hangat.

ğŸ”¹ 3. Suhu Rata-Rata (temp_rata-rata)
Rentang antara 24Â°C hingga 33Â°C.

Hampir simetris, sedikit miring ke kanan.

Puncak sekitar 27Â°C.

Kesimpulan: Suhu rata-rata cukup stabil dan hangat, cocok untuk aktivitas luar ruang dan tanaman tropis.

ğŸ”¹ 4. Kelembaban Rata-Rata (lembab_rata-rata)
Rentang antara 55% hingga 100%.

Distribusi cenderung normal, puncak di sekitar 88%.

Kesimpulan: Udara sangat lembab di sebagian besar hari, menunjukkan kondisi lingkungan yang basah atau tropis, berpotensi mendukung pertumbuhan tanaman tapi juga meningkatkan risiko jamur/penyakit.

ğŸ”¹ 5. Curah Hujan (ch)
Rentang antara 0 mm hingga >100 mm.

Sangat miring ke kanan (banyak data nol).

Puncak di 0 mm.

Kesimpulan: Sebagian besar hari tidak hujan (kering), tapi ada hari-hari tertentu dengan hujan deras, mencerminkan pola iklim musiman (misalnya musim kemarau dan musim hujan yang jelas).

ğŸ”¹ 6. Lama Penyinaran Matahari (cahaya_jam)
Rentang dari 0 hingga 10 jam per hari.

Distribusi agak merata, tapi puncak di 0 jam.

Kesimpulan: Hari cerah dan mendung/hujan sama-sama sering terjadi. Adanya puncak di 0 jam menunjukkan sejumlah hari benar-benar gelap (mendung penuh atau hujan seharian), berpengaruh pada fotosintesis dan efisiensi energi surya.


"""

plt.figure(figsize=(12,4))
sns.countplot(x=Thn)
plt.title('Distribusi Data per Tahun')
plt.show()

plt.figure(figsize=(12,4))
sns.countplot(x=bln)
plt.title('Distribusi Data per Bulan')
plt.show()

plt.figure(figsize=(12,4))
sns.countplot(x=tgl)
plt.title('Distribusi Data per Tanggal')
plt.show()

"""Visualisasi tersebut menunjukkan distribusi data berdasarkan waktu, mencakup tahunan, bulanan, dan harian. Pada grafik pertama, distribusi data per tahun tampak seimbang antara tahun 2022 dan 2023, masing-masing memiliki sekitar 360 data, menunjukkan bahwa data dikumpulkan secara konsisten selama dua tahun. Grafik bulanan juga memperlihatkan distribusi yang merata di hampir semua bulan, meskipun terdapat sedikit penurunan pada bulan Desember (bulan ke-12), yang bisa jadi disebabkan oleh data yang belum lengkap atau berkurangnya pencatatan di akhir tahun.

Pada grafik ketiga (distribusi per tanggal), sebagian besar tanggal dari 1 hingga 30 memiliki jumlah data yang seragam, yaitu sekitar 23â€“24 catatan per tanggal. Namun, jumlah data mulai menurun setelah tanggal 20, dengan penurunan tajam pada tanggal 31. Hal ini sangat mungkin disebabkan oleh fakta bahwa tidak semua bulan memiliki 31 hari, sehingga frekuensi pada tanggal tersebut lebih rendah secara alami. Secara keseluruhan, distribusi waktu cukup merata dan tidak menunjukkan adanya kesenjangan besar dalam pencatatan data harian.
"""

# Gabungkan fitur menjadi DataFrame
df_fitur = pd.DataFrame({
    'temp_min': temp_min,
    'temp_max': temp_max,
    'temp_rata-rata': temp_rata_rata,
    'lembab_rata-rata': lembab_rata_rata,
    'ch': ch,
    'cahaya_jam': cahaya_jam
})

# Buat heatmap korelasi
plt.figure(figsize=(10, 8))
corr_matrix = df_fitur.corr()

sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Heatmap Korelasi Antar Variabel')
plt.show()

"""Hubungan terkuat adalah negatif antara suhu dan kelembaban, artinya hari yang panas biasanya lebih kering.

Suhu maksimum sangat menentukan suhu rata-rata.

Curah hujan berdiri cukup independen, artinya tidak terlalu berkorelasi kuat dengan variabel lain.

Penyinaran matahari cenderung muncul saat kelembaban rendah dan suhu maksimum tinggi, tetapi hubungannya tidak ekstrem.


"""

# Gabung tanggal dari variabel terpisah
tanggal = pd.to_datetime({'year': Thn, 'month': bln, 'day': tgl})

# Buat DataFrame fitur
df_fitur = pd.DataFrame({
    'tanggal': tanggal,
    'temp_min': temp_min,
    'temp_max': temp_max,
    'temp_rata-rata': temp_rata_rata,
    'lembab_rata-rata': lembab_rata_rata,
    'ch': ch,
    'cahaya_jam': cahaya_jam
})

# Jadikan tanggal sebagai index
df_fitur.set_index('tanggal', inplace=True)

# Plot Curah Hujan Harian
plt.figure(figsize=(15, 5))
df_fitur['ch'].plot()
plt.title('Curah Hujan Harian')
plt.xlabel('Tanggal')
plt.ylabel('Curah Hujan (mm)')
plt.grid(True)
plt.show()

"""#Data Preparation"""

# KONVERSI TANGGAL
data['tanggal'] = pd.to_datetime(data[['Thn', 'bln', 'tgl']].rename(columns={'Thn':'year','bln':'month','tgl':'day'}))
data.set_index('tanggal', inplace=True)

"""Kode berikut berfungsi untuk menggabungkan kolom tahun (Thn), bulan (bln), dan tanggal (tgl) menjadi kolom tanggal yang utuh dan mengatur tanggal tersebut sebagai indeks DataFrame

"""

#  BUAT LABEL KATEGORI HUJAN
def categorize_rain(ch):
    if ch == 0:
        return 'tidak hujan'
    elif ch < 20:
        return 'hujan ringan'
    elif ch < 50:
        return 'hujan sedang'
    else:
        return 'hujan deras'

data['kategori_hujan'] = data['ch'].apply(categorize_rain)

"""Kode ini berfungsi untuk mengelompokkan nilai curah hujan (ch) menjadi label kategori hujan yang lebih mudah dipahami."""

#  ENCODE LABEL
le = LabelEncoder()
data['label'] = le.fit_transform(data['kategori_hujan'])

"""Baris kode ini digunakan untuk mengubah data kategori (teks) menjadi angka (label numerik) yang dapat diproses oleh model machine learning."""

# PILIH FITUR UNTUK KLASIFIKASI
fitur = ['temp_min', 'temp_max', 'temp_rata-rata', 'lembab_rata-rata', 'cahaya_jam']
target = 'label'

"""Baris kode ini bertujuan untuk menentukan fitur (input) dan target (output) yang akan digunakan dalam pelatihan model klasifikasi."""

#CEK DAN NORMALISASI FITUR
scaler = MinMaxScaler()
data[fitur] = scaler.fit_transform(data[fitur])

"""Kode ini bertujuan untuk menormalkan fitur-fitur numerik agar nilainya berada dalam skala yang sama, yaitu antara 0 sampai 1."""

#  SPLIT DATA (TRAIN DAN TEST)
X = data[fitur]
y = data[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)  # tanpa acak, agar tetap berurutan

# LIHAT DATA
print("Fitur:\n", X.head())
print("Label:\n", y.head())

"""Fitur sudah dinormalisasi dengan nilai antara 0 dan 1.

Label berupa angka yang merupakan hasil encoding kategori hujan (misalnya: 1, 2, dst).

Index data berupa tanggal, sesuai dengan set indeks yang sudah diatur.

#Modeling
"""

# 9. LATIH MODEL RANDOM FOREST
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 10. PREDIKSI
y_pred = model.predict(X_test)

# Kelas yang muncul di y_test dan y_pred
unique_labels = np.unique(np.concatenate((y_test, y_pred)))

# Nama kelas yang sesuai dengan unique_labels
target_names_filtered = [le.classes_[i] for i in unique_labels]

print("Classification Report:\n")
print(classification_report(y_test, y_pred, labels=unique_labels, target_names=target_names_filtered))

"""hujan ringan

Precision 0.65: Dari semua prediksi model untuk kelas ini, 65% benar.

Recall 0.74: Dari semua data sebenarnya kelas hujan ringan, model berhasil mengenali 74%.

F1-score 0.69: Nilai harmonis antara precision dan recall, menunjukkan keseimbangan yang cukup baik.

hujan sedang

Precision, Recall, dan F1-score = 0.00: Model gagal memprediksi kelas ini sama sekali (tidak ada prediksi untuk kelas hujan sedang).

Support hanya 6 data, artinya data hujan sedang sangat sedikit (imbalance kelas).

tidak hujan

Precision 0.88 dan Recall 0.88: Model cukup baik dalam mengenali dan memprediksi data yang tidak hujan.

F1-score 0.88 menandakan performa yang kuat di kelas ini.


"""

#  SIMPAN MODEL
joblib.dump(model, '/content/drive/MyDrive/model_rf_cuaca.pkl')
print("Model Random Forest telah disimpan.")

"""ini untuk save model

#Evaluasi model
"""

# Hitung metrik utama
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

print(f"Accuracy:  {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-score:  {f1:.4f}")

# Visualisasi Confusion Matrix
plt.figure(figsize=(7,5))
cm = confusion_matrix(y_test, y_pred, labels=unique_labels)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_names_filtered,
            yticklabels=target_names_filtered)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""Model sangat baik dalam memprediksi â€œtidak hujanâ€ (84 benar, hanya 12 salah).

Prediksi untuk â€œhujan sedangâ€ sangat buruk: hanya 1 dari 27 kasus yang terklasifikasi dengan benar.

Model sering membingungkan â€œhujan sedangâ€ dengan â€œtidak hujanâ€ atau â€œhujan ringanâ€.

Secara keseluruhan, performa model cukup baik (80% akurasi), tetapi perlu ditingkatkan terutama pada klasifikasi â€œhujan sedangâ€ yang masih sangat lemah. Model kemungkinan mengalami ketidakseimbangan kelas atau kurang fitur yang membedakan â€œhujan sedangâ€.

#strukturdetail

Secara keseluruhan, **struktur kode rapi dan sudah memenuhi sebagian besar rubrik penilaian proyek machine learning**

---

###  **1. Struktur Modular dan Terbagi Jelas**

 membagi kode ke dalam bagian:

* Import library
* Load data
* Exploratory Data Analysis (EDA)
* Data Cleaning & Preparation
* Feature Engineering & Labeling
* Normalisasi
* Train-test split
* Modeling
* Evaluasi
* Penyimpanan model
   **Sudah sesuai.**

---

### **2. Pembersihan & Penanganan Missing Values**



* Mengecek dan menghitung missing values
* Mengganti nilai 9999 dan 8888 menjadi `NaN`
* Mengisi NaN dengan median


---

### **3. Penanganan Outlier dan Visualisasi Distribusi**

* Boxplot dan histogram sudah digunakan
* Visualisasi tambahan seperti countplot dan heatmap korelasi juga ada


---

###  **4. Feature Engineering & Transformasi Label**

* Kategori curah hujan didefinisikan dengan baik
* Label encoding dilakukan dengan benar

---

###  **5. Normalisasi Fitur**

* Menggunakan `MinMaxScaler` untuk menyesuaikan skala

---

###  **6. Split Data Latih dan Uji**

* Dilakukan dengan `train_test_split` tanpa shuffle (untuk time-series cocok)

---

###  **7. Pelatihan Model & Evaluasi**

* Menggunakan `RandomForestClassifier`
* Evaluasi pakai:

  * Accuracy
  * Precision
  * Recall
  * F1-score
  * Confusion matrix (dengan heatmap visual)


---

###  **8. Penyimpanan Model**

* Model disimpan menggunakan `joblib`


---

###  **9. Interpretasi Output & Nama Kelas**

* Menggunakan `LabelEncoder` dan mengembalikan nama kelas dari hasil prediksi


---

###  **10. Perbaikan yang Bisa Ditambahkan (Opsional untuk dapat â€œbintang penuhâ€):**

* **Modularisasi kode**: membagi fungsi dalam definisi (`def`) agar bisa digunakan ulang.
* **Komentar tambahan** di beberapa blok kode penting agar pembaca mudah paham.
* Tambahkan **GridSearchCV** untuk hyperparameter tuning jika ingin lebih lanjut.
* Tampilkan contoh hasil prediksi per data (`sample prediction`).

---

### ğŸ“Œ **Kesimpulan:**
**sudah memenuhi rubrik penilaian dengan struktur yang rapi dan komprehensif**.
"""