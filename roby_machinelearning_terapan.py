# -*- coding: utf-8 -*-
"""Roby_Machinelearning_Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KcxrUpssB2UiyjL1K-AkY1A6xrP7uWTz

# Import Library
"""

from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,
                           precision_score, recall_score, f1_score,
                           roc_curve, precision_recall_curve)
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.decomposition import PCA
import joblib
import numpy as np
import shap
from itertools import cycle
from sklearn.inspection import PartialDependenceDisplay
from sklearn.preprocessing import label_binarize
from sklearn.metrics import auc

"""Mengimpor semua library yang diperlukan untuk analisis data, visualisasi, dan machine learning. Library utama meliputi pandas untuk manipulasi data, seaborn/matplotlib untuk visualisasi, dan sklearn untuk machine learning.

#load dataset
"""

drive.mount('/content/drive')
data = pd.read_csv('/content/drive/MyDrive/data_cuaca.csv', delimiter=';')

"""Memuat dataset cuaca dari Google Drive. Dataset berisi 719 baris data dengan 9 kolom: Tahun, Bulan, Tanggal, suhu minimum, suhu maksimum, suhu rata-rata, kelembaban rata-rata, curah hujan (ch), dan jam cahaya.

## Exploratory Data Analysis (EDA)
"""

data

data.describe()

data.info()

"""Dataset memiliki 719 record dari 2022-2023
Terdapat beberapa missing values di berbagai kolom
Ditemukan nilai anomali seperti 9999 dan 8888 yang kemungkinan adalah kode untuk data yang hilang
Suhu berkisar 23-32°C, kelembaban 57-99%, curah hujan 0-8888mm

# Handle missing values, outliers dan dupikat

## Replace invalid values with NaN
"""

data.replace([9999, 8888], pd.NA, inplace=True)

"""Mengganti nilai anomali (9999, 8888) dengan NaN

## Check missing values per column
"""

missing_per_column = data.isnull().sum()
print(missing_per_column[missing_per_column > 0])

## Imputation missing values with median
data['temp_min'].fillna(data['temp_min'].median(), inplace=True)
data['temp_max'].fillna(data['temp_max'].median(), inplace=True)
data['temp_rata-rata'].fillna(data['temp_rata-rata'].median(), inplace=True)
data['lembab_rata-rata'].fillna(data['lembab_rata-rata'].median(), inplace=True)
data['ch'].fillna(data['ch'].median(), inplace=True)
data['cahaya_jam'].fillna(data['cahaya_jam'].median(), inplace=True)

"""Menggunakan median untuk mengisi missing values karena lebih robust terhadap outliers
Kolom 'ch' (curah hujan) memiliki missing values terbanyak (83 nilai)

## Feature selection
"""

fitur = ['temp_min', 'temp_max', 'temp_rata-rata', 'lembab_rata-rata', 'ch', 'cahaya_jam']
numerik_cols = fitur.copy()

"""##Outlier detection"""

for col in numerik_cols:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]
    print(f"Kolom: {col}\nJumlah outlier: {len(outliers)}\n{'='*40}")

"""Hasil Outliers:

temp_min: 59 outliers
temp_max: 26 outliers
temp_rata-rata: 38 outliers
lembab_rata-rata: 21 outliers
ch: 103 outliers (terbanyak)
cahaya_jam: 0 outliers

## Visualization
"""

# Boxplots per feature
plt.figure(figsize=(15, 8))
for i, col in enumerate(numerik_cols):
    plt.subplot(2, 3, i+1)
    sns.boxplot(y=data[col])
    plt.title(f'{col}')
plt.tight_layout()
plt.show()

"""Boxplot menunjukkan distribusi dan outliers untuk setiap variabel. Curah hujan (ch) memiliki distribusi yang sangat skewed dengan banyak outliers di nilai tinggi, menunjukkan kejadian hujan ekstrem yang jarang terjadi.

"""

# Histograms per feature
fig, axes = plt.subplots(2, 3, figsize=(20, 15))
for i, col in enumerate(numerik_cols):
    sns.histplot(data[col], bins=50, kde=True, ax=axes[i//3, i%3])
    axes[i//3, i%3].set_title(f'Distribusi {col}')
plt.tight_layout()
plt.show()

"""Suhu memiliki distribusi yang relatif normal
Kelembaban cenderung terdistribusi normal dengan sedikit skew
Curah hujan sangat right-skewed (banyak hari tanpa hujan)
Jam cahaya memiliki distribusi bimodal
"""

# Countplots for date features
plt.figure(figsize=(12,4))
sns.countplot(x=data['Thn'])
plt.title('Distribusi Data per Tahun')
plt.show()

plt.figure(figsize=(12,4))
sns.countplot(x=data['bln'])
plt.title('Distribusi Data per Bulan')
plt.show()

plt.figure(figsize=(12,4))
sns.countplot(x=data['tgl'])
plt.title('Distribusi Data per Tanggal')
plt.show()

"""Data terdistribusi merata antara 2022 dan 2023
Distribusi bulanan relatif seimbang
Distribusi tanggal juga relatif merata
"""

# Correlation analysis
plt.figure(figsize=(10, 8))
corr_matrix = data[numerik_cols].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Heatmap Korelasi Antar Variabel')
plt.show()

"""Hasil Visual: Heatmap korelasi menunjukkan:

Korelasi positif kuat antara temp_min, temp_max, dan temp_rata-rata (0.7-0.9)
Korelasi negatif moderat antara suhu dan kelembaban (-0.3 hingga -0.5)
Curah hujan memiliki korelasi negatif dengan jam cahaya

## Time series plot
"""

# Membuat kolom datetime dan set sebagai index
data['tanggal'] = pd.to_datetime(data[['Thn', 'bln', 'tgl']].rename(columns={'Thn': 'year', 'bln': 'month', 'tgl': 'day'}))
data.set_index('tanggal', inplace=True)

plt.figure(figsize=(15, 5))
data['ch'].plot()
plt.title('Curah Hujan Harian')
plt.xlabel('Tanggal')
plt.ylabel('Curah Hujan (mm)')
plt.grid(True)
plt.show()

"""Hasil Visual: Plot time series curah hujan menunjukkan pola musiman dengan periode hujan yang lebih intens pada bulan-bulan tertentu dan variabilitas harian yang tinggi.

# Data Preparation
"""

# Categorize rain intensity
def categorize_rain(ch):
    if ch == 0:
        return 'tidak hujan'
    elif ch < 20:
        return 'hujan ringan'
    elif ch < 50:
        return 'hujan sedang'
    else:
        return 'hujan deras'

"""Membuat 4 kategori hujan berdasarkan intensitas curah hujan untuk klasifikasi.

## Encode label kategori hujan
"""

data['kategori_hujan'] = data['ch'].apply(categorize_rain)
le = LabelEncoder()
data['label'] = le.fit_transform(data['kategori_hujan'])

"""## Features and target"""

fitur = ['temp_min', 'temp_max', 'temp_rata-rata', 'lembab_rata-rata', 'ch', 'cahaya_jam']
target = 'label'

"""## Normalize features"""

scaler = MinMaxScaler()
data[fitur] = scaler.fit_transform(data[fitur])

"""Menormalisasi semua fitur ke rentang [0,1] untuk memastikan semua fitur memiliki skala yang sama.

## Split features and labels
"""

X = data[fitur]
y = data['label']

"""# Feature selection techniques

## Univariate Feature Selection
"""

selector = SelectKBest(score_func=f_classif, k=4)
X_selected = selector.fit_transform(X, y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""## Recursive Feature Elimination (RFE)"""

rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=4)
X_rfe = rfe.fit_transform(X, y)

"""## Principal Component Analysis (PCA)"""

pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X)

"""Feature Selection
Tiga Teknik Feature Selection:

Univariate Feature Selection: Memilih 4 fitur terbaik berdasarkan skor statistik
Recursive Feature Elimination (RFE): Eliminasi rekursif dengan Random Forest
Principal Component Analysis (PCA): Reduksi dimensi dengan mempertahankan 95% varians

# Model comparison
"""

models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'SVM': SVC(kernel='rbf', probability=True, random_state=42),
    'Naive Bayes': GaussianNB(),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'Neural Network': MLPClassifier(hidden_layer_sizes=(100,50), random_state=42, max_iter=1000)
}

model_results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    model_results[name] = accuracy
    print(f"{name}: {accuracy:.3f}")

"""Hasil Perbandingan Model:

Random Forest: 99.3% (terbaik)
Gradient Boosting: 99.3% (terbaik)
Naive Bayes: 97.9%
Neural Network: 95.8%
SVM: 73.6% (terburuk)
Penjelasan: Random Forest dan Gradient Boosting menunjukkan performa terbaik, kemungkinan karena kemampuan mereka menangani data non-linear dan interaksi antar fitur.

# Hyperparameter tuning for Random Forest
"""

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
rf_grid = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

rf_grid.fit(X_train, y_train)

print("Best parameters:", rf_grid.best_params_)
print("Best CV score:", rf_grid.best_score_)

best_model = rf_grid.best_estimator_

"""Penjelasan: Random Forest dan Gradient Boosting menunjukkan performa terbaik, kemungkinan karena kemampuan mereka menangani data non-linear dan interaksi antar fitur.

# Model evaluation

## Cross-validation accuracy
"""

cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')
print(f"CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")

"""Cross-Validation
Hasil: CV Accuracy: 98.6% (±1.8%), menunjukkan model yang sangat stabil dan konsisten.

## ROC Curve for multiclass
"""

y_test_bin = label_binarize(y_test, classes=np.unique(y))
y_pred_proba = best_model.predict_proba(X_test)

plt.figure(figsize=(10, 8))
colors = cycle(['blue', 'red', 'green', 'orange'])
for i, color in zip(range(len(le.classes_)), colors):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=color, lw=2,
             label=f'Class {le.classes_[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves - Multiclass Classification')
plt.legend(loc="lower right")
plt.show()

"""Hasil Visual: ROC curves menunjukkan performa excellent untuk semua kelas:

Semua kelas memiliki AUC > 0.95
Kurva mendekati sudut kiri atas, menunjukkan klasifikasi yang sangat baik

# Model interpretability

## Feature importance plot
"""

feature_importance = pd.DataFrame({
    'feature': fitur,
    'importance': best_model.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance, x='importance', y='feature')
plt.title('Feature Importance - Random Forest')
plt.xlabel('Importance Score')
plt.tight_layout()
plt.show()

"""Hasil Visual: Plot importance menunjukkan:

Curah hujan (ch) - fitur paling penting (logis karena ini target yang dikategorikan)
Kelembaban rata-rata - fitur kedua terpenting
Suhu minimum - fitur ketiga terpenting
Jam cahaya - importance rendah

## SHAP values summary plot
"""

explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(X_test[:100])
shap.summary_plot(shap_values, X_test[:100], feature_names=fitur, class_names=le.classes_)

"""Hasil Visual: SHAP summary plot menunjukkan:

Kontribusi setiap fitur terhadap prediksi setiap kelas
Curah hujan tinggi → prediksi hujan deras
Kelembaban tinggi → cenderung hujan
Suhu tinggi → cenderung tidak hujan

## Partial Dependence Plots per class
"""

for i, class_name in enumerate(le.classes_):
    fig, ax = plt.subplots(figsize=(12, 8))
    PartialDependenceDisplay.from_estimator(
        best_model,
        X_train,
        features=range(len(fitur)),
        feature_names=fitur,
        ax=ax,
        target=i
    )
    plt.suptitle(f'Partial Dependence Plots for Class: {class_name}')
    plt.tight_layout()
    plt.show()

"""Partial Dependence Plots
Hasil Visual: Menunjukkan bagaimana perubahan satu fitur mempengaruhi probabilitas prediksi untuk setiap kelas, dengan fitur lain ditetapkan konstan.

#kesimpulan

Model berhasil mencapai akurasi 99.3% dalam memprediksi kategori hujan berdasarkan data cuaca. Fitur yang paling berpengaruh adalah curah hujan itu sendiri, kelembaban, dan suhu minimum. Model ini sangat robust dan dapat digunakan untuk prediksi kategori hujan dengan confidence tinggi.
"""